{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "8aff099d-a933-4df4-98a6-a9a583f2de73",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "HTTP Error 404: Not Found\n"
     ]
    }
   ],
   "source": [
    "from urllib.request import urlopen\n",
    "from urllib.error import HTTPError\n",
    "from urllib.error import URLError\n",
    "\n",
    "try:\n",
    "  html = urlopen('http://pythonscraping.com/pages/page1.htmll')\n",
    "except HTTPError as e:  \n",
    "  print(e)\n",
    "except URLError as e:  \n",
    "  print(\"The server could not be found!\")\n",
    "else:\n",
    "  print(\"It Worked!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "4dab20bd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: bs4 in c:\\python312\\lib\\site-packages (0.0.2)\n",
      "Requirement already satisfied: beautifulsoup4 in c:\\python312\\lib\\site-packages (from bs4) (4.12.3)\n",
      "Requirement already satisfied: soupsieve>1.2 in c:\\python312\\lib\\site-packages (from beautifulsoup4->bs4) (2.6)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "[notice] A new release of pip is available: 24.0 -> 24.3.1\n",
      "[notice] To update, run: python.exe -m pip install --upgrade pip\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting html5lib\n",
      "  Downloading html5lib-1.1-py2.py3-none-any.whl.metadata (16 kB)\n",
      "Requirement already satisfied: six>=1.9 in c:\\users\\14433\\appdata\\roaming\\python\\python312\\site-packages (from html5lib) (1.16.0)\n",
      "Collecting webencodings (from html5lib)\n",
      "  Using cached webencodings-0.5.1-py2.py3-none-any.whl.metadata (2.1 kB)\n",
      "Downloading html5lib-1.1-py2.py3-none-any.whl (112 kB)\n",
      "   ---------------------------------------- 0.0/112.2 kB ? eta -:--:--\n",
      "   --- ------------------------------------ 10.2/112.2 kB ? eta -:--:--\n",
      "   ------------------------------------ --- 102.4/112.2 kB 1.5 MB/s eta 0:00:01\n",
      "   ---------------------------------------- 112.2/112.2 kB 1.3 MB/s eta 0:00:00\n",
      "Using cached webencodings-0.5.1-py2.py3-none-any.whl (11 kB)\n",
      "Installing collected packages: webencodings, html5lib\n",
      "Successfully installed html5lib-1.1 webencodings-0.5.1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "[notice] A new release of pip is available: 24.0 -> 24.3.1\n",
      "[notice] To update, run: python.exe -m pip install --upgrade pip\n"
     ]
    }
   ],
   "source": [
    "!pip install bs4\n",
    "!pip install html5lib"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "55097faa-72a3-495c-8b1b-180f54cd5ad3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<h1>An Interesting Title</h1>\n"
     ]
    }
   ],
   "source": [
    "from urllib.request import urlopen\n",
    "from bs4 import BeautifulSoup\n",
    "\n",
    "html = urlopen('http://www.pythonscraping.com/pages/page1.html')\n",
    "bs = BeautifulSoup(html.read(), 'html.parser') # (string that object is based on, specified parser to use)\n",
    "print(bs.h1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ff8dd1bd",
   "metadata": {},
   "source": [
    "**The scraper below comes with more advanced handling to handle potential errors such as:**\n",
    "\n",
    "  * HTTP error - url is found but file/filepath isn't found\n",
    "  * Url error - no url found\n",
    "  * Attribute error - missing attribute like h1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "b2aaf008",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<h1>An Interesting Title</h1>\n"
     ]
    }
   ],
   "source": [
    "from urllib.request import urlopen\n",
    "from urllib.error import HTTPError\n",
    "from urllib.error import URLError\n",
    "from bs4 import BeautifulSoup\n",
    "\n",
    "def getTitle(url):\n",
    "    try:\n",
    "        html = urlopen(url)\n",
    "    except HTTPError as e:\n",
    "        return None\n",
    "    except URLError as e:\n",
    "        print(\"The server could not be found!\")\n",
    "        return None\n",
    "    try:\n",
    "        bs = BeautifulSoup(html.read(), 'html.parser')\n",
    "        title = bs.body.h1\n",
    "    except AttributeError as e:\n",
    "        return None\n",
    "    return title\n",
    "\n",
    "title = getTitle(\"http://www.pythonscraping.com/pages/page1.html\")\n",
    "if title == None:\n",
    "  print(\"Title could not be found\")\n",
    "else:\n",
    "    print(title)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3e1e9128",
   "metadata": {},
   "source": [
    "**This section covers searching for tags by attributes, working with lists of tags, and navigating parse trees**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9d24b179",
   "metadata": {},
   "source": [
    "This subsection will focus on parsing html that has css styling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7b89387c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Anna\n",
      "Pavlovna Scherer\n",
      "Empress Marya\n",
      "Fedorovna\n",
      "Prince Vasili Kuragin\n",
      "Anna Pavlovna\n",
      "St. Petersburg\n",
      "the prince\n",
      "Anna Pavlovna\n",
      "Anna Pavlovna\n",
      "the prince\n",
      "the prince\n",
      "the prince\n",
      "Prince Vasili\n",
      "Anna Pavlovna\n",
      "Anna Pavlovna\n",
      "the prince\n",
      "Wintzingerode\n",
      "King of Prussia\n",
      "le Vicomte de Mortemart\n",
      "Montmorencys\n",
      "Rohans\n",
      "Abbe Morio\n",
      "the Emperor\n",
      "the prince\n",
      "Prince Vasili\n",
      "Dowager Empress Marya Fedorovna\n",
      "the baron\n",
      "Anna Pavlovna\n",
      "the Empress\n",
      "the Empress\n",
      "Anna Pavlovna's\n",
      "Her Majesty\n",
      "Baron\n",
      "Funke\n",
      "The prince\n",
      "Anna\n",
      "Pavlovna\n",
      "the Empress\n",
      "The prince\n",
      "Anatole\n",
      "the prince\n",
      "The prince\n",
      "Anna\n",
      "Pavlovna\n",
      "Anna Pavlovna\n"
     ]
    }
   ],
   "source": [
    "from urllib.request import urlopen\n",
    "from bs4 import BeautifulSoup\n",
    "\n",
    "html = urlopen('http://www.pythonscraping.com/pages/warandpeace.html')\n",
    "bs = BeautifulSoup(html.read(), 'html.parser')\n",
    "\n",
    "# use find all to extract a python list of proper nouns found by selecting only the text within <specifiedTag></specifiedTag>\n",
    "name_list = bs.find_all('span', {'class':'green'}) # (tagName, tagAttributes)\n",
    "for name in name_list:\n",
    "  print(name.get_text()) # .get_text strips all tags from the document you are working with and returns a Unicode string containing the text (within those tags) only"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "94695f87",
   "metadata": {},
   "source": [
    "Calling '.get_text' should always be the last thing you do, immediately before you print, store, or manipulate your final data.\n",
    "In general, try to preserve the tag structure of a document as long as possible\n",
    "\n",
    "In this next subsection, 'find()' and 'find_all()' with 'BeautifulSoup' will be discussed"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4f58a985",
   "metadata": {},
   "source": [
    "The functions are very similar:\n",
    "  * find_all(tag, attrs, recursive, text, limit, **kwargs)\n",
    "  * find(tag, attrs, recursive, text, **kwargs)\n",
    "\n",
    "95% of the time you will only need to use the first 2 arguments:\n",
    "  * tag\n",
    "  * attributes\n",
    "\n",
    "In find_all tag parameter, you can pass a sting tag name or a list of string tag names:\n",
    "  * find_all('h1')\n",
    "  * find_all(['h1', 'h2', 'h3', 'h4', 'h5', 'h6']) --> which returns a list of all the header tags in a document\n",
    "\n",
    "The attributes (attrs) must be a python dictionary of attributes and values\n",
    "The following function will return BOTH the green and red span tags in the HTML document:\n",
    "  * .find_all('span', {'class': ['green', 'red']})\n",
    "\n",
    "The recursive parameter is a boolean. How deep into the document do you want to go?\n",
    "If recursive is set to True, the 'find_all' function looks into children, and childrens children, etc., for tags that match the parameters.\n",
    "If recursive is false, it will only look at top-level tags\n",
    "\n",
    "by default 'find_all' recursive parameter is set to true\n",
    "\n",
    "The 'text' parameter matches based on the text content in the tags themselves\n",
    "  * nameList = bs.find_all(text=\"the prince\")\n",
    "  * print(len(nameList)) --> 7\n",
    "\n",
    "The 'limit' parameter is set if you want to retrieve the first x items from a page.\n",
    "This only gives you the first items on the page in the order they occur, not necessarily the first ones you want\n",
    "\n",
    "The **kwargs parameter allows you to pass any additional named arguments you want into the method.\n",
    "Any extra arguments that 'find' or 'find_all' doesn't recognize will be used as tag attribute matchers:\n",
    "  * title = bs.find_all(id='title', class='text')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "374b491c",
   "metadata": {},
   "source": [
    "**Navigating Trees**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d0bf9a95",
   "metadata": {},
   "source": [
    "This section will focus on navigating HTML trees. Not just downward but up, across, and diagonally\n",
    "\n",
    "BeautifulSoup functions always deal with the descendants of the current tag selected"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
